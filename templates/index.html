<!DOCTYPE html>
<html lang="ja" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat with Voice</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/font-awesome@6/css/all.min.css" rel="stylesheet">
    <link href="{{ url_for('static', filename='css/style.css') }}" rel="stylesheet">
</head>
<body>
    <div id="parentContainer">
        <div class="image-container" id="characterbody"></div>
        <div class="image-container" id="mouse"></div>
        <div class="image-container" id="face"></div>
    </div>

    <div class="container py-4">
        <div class="speaker-select">
            <h3 class="mb-3">音声設定</h3>
            <div class="row">
                <div class="col-md-6">
                    <div class="mb-3">
                        <label for="speaker-a">話者A（主回答）</label>
                        <select id="speaker-a" class="form-select mb-2"></select>
                        <label for="style-a">話者Aの声色</label>
                        <select id="style-a" class="form-select"></select>
                    </div>
                </div>
                <div class="col-md-6">
                    <div class="mb-3">
                        <label for="speaker-b">話者B（リアクション）</label>
                        <select id="speaker-b" class="form-select mb-2"></select>
                        <label for="style-b">話者Bの声色</label>
                        <select id="style-b" class="form-select"></select>
                    </div>
                </div>
            </div>
        </div>

        <div class="chat-container">
            <div id="chat-messages" class="chat-messages"></div>

            <div class="input-group">
                <input type="text" id="user-input" class="form-control" placeholder="メッセージを入力...">
                <button class="btn btn-primary" id="send-button">
                    <i class="fas fa-paper-plane"></i> 送信
                </button>
            </div>
        </div>
    </div>

    <script src="{{ url_for('static', filename='js/chat.js') }}"></script>
    <script>
        let ctx = null // AudioContext: Nodeの作成、音声のデコードの制御などを行う
        let audioSrc = null // AudioBufferSourceNode: 音声入力ノード
        let analyser = null // AnalyserNode: 音声解析ノード
        let sampleInterval = null
        let prevSpec = 0 // 前回のサンプリングで取得したスペクトルの配列
        const mouseElement = document.getElementById('mouse');

        /* 音声データをAudioBufferに変換 */
        async function preparedBuffer(voice_path) {
            ctx = new AudioContext()
            const res = await fetch(voice_path)
            const arrayBuffer = await res.arrayBuffer()
            const audioBuffer = await ctx.decodeAudioData(arrayBuffer)
            return audioBuffer
        }

        /* 入力ノード、Analyserノードを生成し、出力層に接続 */
        function buildNodes(audioBuffer) {
            audioSrc = new AudioBufferSourceNode(ctx, { buffer: audioBuffer })
            analyser = new AnalyserNode(ctx)
            analyser.fftSize = 512
            audioSrc.connect(analyser).connect(ctx.destination)
        }

        /* スペクトルをもとにリップシンクを行う */
        function syncLip(spectrums, voicevox_id) {
            let totalSpec = 0
            const vocalRangeSpectrums = spectrums.slice(0, spectrums.length / 2)
            const totalSpectrum = vocalRangeSpectrums.reduce((a, x) => a + x, 0)
            console.log("spec: " + (prevSpec - totalSpectrum));

            if (voicevox_id == 6) { // 四国めたん
                if (totalSpectrum > prevSpec) {
                    mouseElement.style.backgroundImage = "url('/static/assets/metan_mouse_open.png')";
                } else if (prevSpec - totalSpectrum < 250) {
                    mouseElement.style.backgroundImage = "url('/static/assets/metan_mouse_open_middle.png')";
                } else if (prevSpec - totalSpectrum < 500) {
                    mouseElement.style.backgroundImage = "url('/static/assets/metan_mouse_close_middle.png')";
                } else {
                    mouseElement.style.backgroundImage = "url('/static/assets/metan_mouse_close.png')";
                }
            }
            prevSpec = totalSpectrum;
        }

        /* 音声再生処理 */
        async function playVoice(voice_path, voicevox_id) {
            console.log("Playing voice...");
            const audioBuffer = await preparedBuffer(voice_path)
            buildNodes(audioBuffer)
            audioSrc.start()

            // 50ms毎に音声のサンプリング→解析→リップシンクを行う
            sampleInterval = setInterval(() => {
                let spectrums = new Uint8Array(analyser.fftSize)
                analyser.getByteFrequencyData(spectrums)
                syncLip(spectrums, voicevox_id)
            }, 50)

            // 音声終了時のコールバック
            audioSrc.onended = () => {
                clearInterval(sampleInterval)
                audioSrc = null
                ctx.close()
                ctx = null
                prevSpec = 0
            }
        }
    </script>
</body>
</html>